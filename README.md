# Intro

*What do we want?*
develop rational design principles for neural network architectures on general curved background with the extendability to quantum situation, i.e.
1. how to choose architecture to speed up the learning ?
2. how to avoid exploding/vanishing gradients?
3. how to avoid being trapped in the local minima during trainin?
4. how many layers and nodes in each layer?
5. how we can transfer learning to different data (steerability)?

*How are we going to achieve this?
We aim to illustrate this phenomenon by constructing coordinate-free deep convolutional neural networks on algebras and answering the questions above.
